{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as palm\n",
    "from langchain.llms import GooglePalm\n",
    "from langchain.chat_models import  ChatGooglePalm\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "palm.configure(api_key= \"AIzaSyAm964k0ZGic7mo1Dbj6VUKqDVorfQ9xKc\")\n",
    "\n",
    "pdf_path = '/Users/sahibsingh05/Documents/code/py/Employee_handbook.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Employees who smoke can drive up an employerâ€™s health care costs andreduce productivity. Get' metadata={'source': '/Users/sahibsingh05/Documents/code/py/Employee_handbook.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, List,Optional\n",
    "from langchain.document_loaders import (Docx2txtLoader, JSONLoader,\n",
    "                                        PyPDFLoader, TextLoader,\n",
    "                                        UnstructuredEmailLoader,\n",
    "                                        UnstructuredHTMLLoader)\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import (CharacterTextSplitter,\n",
    "                                     RecursiveCharacterTextSplitter)\n",
    "import pypdf\n",
    "\n",
    "\n",
    "class CustomException(Exception):\n",
    "       \"\"\"Base class for other exceptions\"\"\"\n",
    "       pass\n",
    "\n",
    "class FileNameError(CustomException):\n",
    "    \"\"\"Raise when the file name provided does not match the given requirements\"\"\"\n",
    "    pass\n",
    "\n",
    "class LoadDocument():\n",
    "    def __init__(self,\n",
    "                jq_schema: Optional[str] = None, \n",
    "                content_key:  Optional[str] = None, \n",
    "                metadata_fields:  Optional[List[str]] = None, \n",
    "                chunk_size: Optional[int] = 100, \n",
    "                chunk_overlap: Optional[int] = 0,\n",
    "                user_metadata: Optional[dict] = {}, \n",
    "                file_id: Optional[str] = None,\n",
    "                data:Optional[str] = None):\n",
    "\n",
    "        self.path = data\n",
    "        self.jq_schema = jq_schema\n",
    "        self.content_key = content_key\n",
    "        self.metadata_fields = metadata_fields\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.user_metadata = user_metadata\n",
    "        self.file_id = file_id\n",
    "        self.data = data\n",
    "\n",
    "    def classify_document(self):\n",
    "        if self.path.endswith('.pdf'): #classify data into file format and use respective loader\n",
    "            self.data =  self.load_pdf()\n",
    "        elif self.path.endswith('.csv'):\n",
    "            self.data =  self.load_csv()\n",
    "        elif self.path.endswith('.html'):\n",
    "            self.data =  self.load_html()\n",
    "        elif self.path.endswith('.json'):\n",
    "            self.data =  self.load_json()\n",
    "        elif self.path.endswith('eml'):\n",
    "            self.ata =  self.load_email()\n",
    "        elif self.path.endswith('txt'):\n",
    "            self.data =  self.load_text()\n",
    "        elif self.path.endswith('docx'):\n",
    "            self.data =  self.load_docx()\n",
    "        else: \n",
    "            raise FileNameError(\"File Type Exception: File Type Not Supported\")\n",
    "    \n",
    "    def split_data(self):\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap)\n",
    "        texts = text_splitter.split_documents(self.data)\n",
    "        # new_texts = []\n",
    "        # for text in texts: \n",
    "        #     if self.file_id: \n",
    "        #         text.metadata.update({\"file_id\": self.file_id})\n",
    "        #     text.metadata.update(self.user_metadata)\n",
    "        #     new_texts.append(text)\n",
    "        # texts = new_texts\n",
    "        # self.hashes = [str(hash(text.page_content)) for text in texts]\n",
    "        self.texts = texts\n",
    "        return texts\n",
    "\n",
    "    def split_texts(self):\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap)\n",
    "        texts = text_splitter.split_text(self.data)\n",
    "        documents = text_splitter.create_documents(texts)\n",
    "        texts = documents\n",
    "        new_texts = []\n",
    "        for text in texts: \n",
    "            text.metadata.update(self.user_metadata)\n",
    "            if self.file_id: \n",
    "                text.metadata.update({\"file_id\": self.file_id})\n",
    "            new_texts.append(text)\n",
    "        texts = new_texts\n",
    "        self.texts = texts\n",
    "        return texts\n",
    "\n",
    "    def load_pdf(self):\n",
    "        loader = PyPDFLoader(self.path)\n",
    "        data = loader.load_and_split()\n",
    "        return data\n",
    "    \n",
    "    def load_csv(self):\n",
    "        loader = CSVLoader(self.path)\n",
    "        data = loader.load()\n",
    "        return data\n",
    "    \n",
    "    def load_html(self):\n",
    "        loader = UnstructuredHTMLLoader(self.path)\n",
    "        data = loader.load()\n",
    "        return data\n",
    "\n",
    "    def metadata_func(self, record: dict, metadata: dict) -> dict:\n",
    "        for metadata_field in self.metadata_fields:\n",
    "            metadata[metadata_field] = record.get(metadata_field)\n",
    "        return metadata\n",
    "\n",
    "    def load_json(self):      \n",
    "        loader = JSONLoader(\n",
    "                file_path=self.path,\n",
    "                jq_schema=jq_schema, #This is the key to the individual json_doc that stores the field. E.g. .messages[]\n",
    "                content_key=content_key, #This is the field name for the text that goes on to become page_content\n",
    "                metadata_func=self.metadata_func \n",
    "            )\n",
    "        data = loader.load()\n",
    "        return data\n",
    "    \n",
    "    def load_email(self):\n",
    "        loader = UnstructuredEmailLoader(self.path)\n",
    "        data = loader.load()\n",
    "        return data\n",
    "    \n",
    "    def load_text(self):\n",
    "        loader = TextLoader(self.path)\n",
    "        data = loader.load()\n",
    "        return data\n",
    "    \n",
    "    def load_docx(self):\n",
    "        loader = Docx2txtLoader(self.path)\n",
    "        data = loader.load()\n",
    "        return data\n",
    "    \n",
    "    def load_array(self):\n",
    "        combined_string = \"\"\n",
    "        for i in self.path: \n",
    "            combined_string += i\n",
    "            combined_string += \" \"\n",
    "        self.data = combined_string\n",
    "\n",
    "pdf_obj = LoadDocument(data = pdf_path)\n",
    "pdf_obj.classify_document()\n",
    "pdf_data = pdf_obj.split_data()\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator= '\\n',\n",
    "    chunk_size = 10000, #size of each segment\n",
    "    chunk_overlap =200 # overlap in segments when the info at ends is important only need for temporaly dependent data\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(pdf_data)\n",
    "print(docs[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.google_palm.embed_with_retry.<locals>._embed_with_retry in 2.0 seconds as it raised ServiceUnavailable: 503 recvmsg:Connection reset by peer.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "\n",
    "embeddings = GooglePalmEmbeddings(google_api_key= \"AIzaSyAm964k0ZGic7mo1Dbj6VUKqDVorfQ9xKc\")\n",
    "vector_store = FAISS.from_documents(docs , embedding= embeddings) #input document and embedding fuction to convert the docs into vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='These policies prohibit harassment and discrimination in the workplace. Clearly state that all', metadata={'source': '/Users/sahibsingh05/Documents/code/py/Employee_handbook.pdf', 'page': 1}), Document(page_content='answers to frequently asked questions aboutanti-smoking policies.', metadata={'source': '/Users/sahibsingh05/Documents/code/py/Employee_handbook.pdf', 'page': 0}), Document(page_content='personal appearance policy:', metadata={'source': '/Users/sahibsingh05/Documents/code/py/Employee_handbook.pdf', 'page': 9}), Document(page_content='state, or local law. Here are 10 policies to avoid:', metadata={'source': '/Users/sahibsingh05/Documents/code/py/Employee_handbook.pdf', 'page': 4})]\n"
     ]
    }
   ],
   "source": [
    "llm = GooglePalm(google_api_key = 'AIzaSyAm964k0ZGic7mo1Dbj6VUKqDVorfQ9xKc')\n",
    "\n",
    "query = \"what do the anti harassement policies state\"\n",
    "answer = vector_store.max_marginal_relevance_search(query)\n",
    "\n",
    "print(answer[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for PromptTemplate\n__root__\n  Invalid prompt schema; check for mismatched or missing input parameters. {'text'} (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m chat_model \u001b[39m=\u001b[39m ChatGooglePalm(google_api_key \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAIzaSyAm964k0ZGic7mo1Dbj6VUKqDVorfQ9xKc\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m prompt \u001b[39m=\u001b[39m PromptTemplate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m input_variables \u001b[39m=\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39mcompany\u001b[39;49m\u001b[39m\"\u001b[39;49m , \u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m , \u001b[39m\"\u001b[39;49m\u001b[39moccupation\u001b[39;49m\u001b[39m\"\u001b[39;49m , \u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m template \u001b[39m=\u001b[39;49m \u001b[39m\"\"\"\u001b[39;49m\u001b[39mYou are a helpful assistant that acts like an HR to a company that \u001b[39;49m\u001b[39m{company}\u001b[39;49;00m\u001b[39m and you\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mre job is going to be helping \u001b[39;49m\u001b[39m{name}\u001b[39;49;00m\u001b[39m who is a \u001b[39;49m\u001b[39m{occupation}\u001b[39;49;00m\u001b[39m at the company with scheduling , leaves , company related questions, reporting another worker and mental support.\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mYou\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mre going to have all knowledge that a \u001b[39;49m\u001b[39m{occupation}\u001b[39;49;00m\u001b[39m needs and going to help them with tasks they need help for. You will not only give advice but also do scheduling\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mand other tasks based on the demand of the worker.\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m ) \u001b[39m# get a prompt template, put the input variables needed as well as the template\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m chain \u001b[39m=\u001b[39m LLMChain(llm\u001b[39m=\u001b[39mllm , prompt \u001b[39m=\u001b[39m prompt) \u001b[39m#define the chain for llm and prompt \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(chain\u001b[39m.\u001b[39mrun({\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcompany\u001b[39m\u001b[39m'\u001b[39m : \u001b[39m\"\u001b[39m\u001b[39mMcDonald\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m : \u001b[39m\"\u001b[39m\u001b[39mJack Harllow\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39moccupation\u001b[39m\u001b[39m'\u001b[39m : \u001b[39m\"\u001b[39m\u001b[39mCashier\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sahibsingh05/Documents/code/py/.ipynb_checkpoints/Square.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m })) \u001b[39m#run the chain with the input variables \u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SquareHack/lib/python3.9/site-packages/langchain/load/serializable.py:90\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SquareHack/lib/python3.9/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[39m'\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for PromptTemplate\n__root__\n  Invalid prompt schema; check for mismatched or missing input parameters. {'text'} (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage , SystemMessage , AIMessage #classes of different messages \n",
    "from langchain.prompts.chat import AIMessagePromptTemplate , HumanMessagePromptTemplate , SystemMessagePromptTemplate #classes for prompts of different categories\n",
    "from langchain.memory import ConversationBufferMemory #stores history of messages exchanged to have conversational aspect\n",
    "from langchain.agents import Tool #abstract class that represents and agent that acts like a chatbot\n",
    "from langchain.agents import AgentType #enum of different type of agents that can be used \n",
    "from langchain.tools import DuckDuckGoSearchRun #tool that can be used for web searches for info\n",
    "from langchain.agents import initialize_agent # use to instantiate and agent of a type \n",
    "\n",
    "chat_model = ChatGooglePalm(google_api_key = 'AIzaSyAm964k0ZGic7mo1Dbj6VUKqDVorfQ9xKc', top_k=40 , top_p=0.8) # k is the number of retrievals and p is the probability threshold\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SquareHack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
